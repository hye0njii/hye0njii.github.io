# hye0njii.github.io

<운전자 졸음 감지>

개인 프로젝트로 진행하였습니다.


Member : 장현지, 전기공학전공, guswl7598@hanyang.ac.kr

I. Proposal
- 졸음운전은 혈중 알코올농도 0.17%의 만취 상태에서 운전하는 것과 같을 정도로 위험하다. 한국도로공사에 따르면 2016~2020 5년간 고속도로 교통사고 사망자 1035명 중 약 70%인 722명이 졸음 및 주시태만으로 인해 발생했다. 이러한 졸음운전을 방지하기 위한 연구들이 진행되고 있다. 이에 OpenCV를 이용하여 운전자의 눈 깜빡임을 판단하는 모델을 운전자 dataset을 통해 테스트하고자 했다. AI Hub의 dataset을 가공하여 사용하고자 했으나, data 처리 과정에 어려움을 겪어 dataset을 변경하고, open source를 이용하여 눈 깜박임을 판단하는 모델을 구현해보았다.


II. Datasets

졸음운전 예방을 위한 운전자 상태 정보 영상 Dataset을 사용할 것이다.

![image](https://user-images.githubusercontent.com/105009129/171202884-d8a9065d-0cd2-4d46-b488-474f619c4ed7.png)

위의 dataset을 사용하고자 했으나, data 처리 과정에 어려움을 겪어 dataset을 변경했다.

https://github.com/kairess/eye_blink_detector/blob/master/README.md
위 github에서 dataset을 다운받아 사용했다.




III. Methodology 

![image](https://user-images.githubusercontent.com/105009129/174095824-6bcfb14a-035f-4bfa-b1b1-02998757dbbb.png)

Colab 환경에서 프로젝트를 진행했기에, Colab 환경 설정을 해주었다.

![image](https://user-images.githubusercontent.com/105009129/174096038-62320699-dd36-4741-a952-45a88f7bf3b9.png)

data를 불러오는 과정이다.
이 부분에서 내가 사용하고자 했던 졸음운전 예방을 위한 운전자 상태 정보 영상 Dataset을 이용하고자 했으나, 기존의 eyes_dataset을 사용했다. 사용한 데이터는 npy 확장자를 가진 이미지다. eyes_dataset이라는 class를 구성했다.

x_file의 shape는 (2586,26,34,1) 즉 2586개 데이터의 width, heigh, channel이 각각 26, 34, 1로 구성되어 있고, 
y_file의 shape는 (2586,1)로 2586개의 데이터 각각의 라벨링이 있다. 각 라벨링은 눈을 감으면 0, 뜨면 1으로 구성되어있다.
이 데이터셋 대신 내가 이용하고자 했던 데이터셋은 image+json file로 구성되어있었는데, 파일 변환 과정을 해결하지 못했다.

![image](https://user-images.githubusercontent.com/105009129/174096461-ae01abd7-6f2b-4026-9710-805a06c21ede.png)
 
 

![image](https://user-images.githubusercontent.com/105009129/174096848-89d9dc3e-c3a7-4a26-b894-966469184df6.png)
input이 (26, 34)일 때의 모델 요약을 불러온 결과이다.



위의 두 파일을 colab 폴더에 각각 저장하여 import 할 수 있도록 했다.



![image](https://user-images.githubusercontent.com/105009129/174097098-aabd78b5-6b8b-4377-a378-9f3c29bbdaad.png)

Colab에서 다른 파일을 import 하기 위해 필요한 import_ipynb를 설치했다.



![image](https://user-images.githubusercontent.com/105009129/174097473-102819ea-00d8-4f8e-8f7f-a0a732449bec.png)

train 하는 과정이다. import import_ipynb를 추가하여 ipynb 확장자의 파일을 import하도록 했다.
npy 확장자를 불러오기 위해 np.load()함수를 사용했다.
x_train, y_train, transform 데이터를 변형한 후, eyes_dataset class를 불러와 데이터들을 넣어주었다.



![image](https://user-images.githubusercontent.com/105009129/174097520-d7ecc19e-873e-464f-a153-473fae308a03.png)

데이터의 라벨링이 잘 되었는지 확인하는 과정이다. 데이터의 총 개수가 2586개여서 len(train_dataset)-2580 으로 range를 조정하여 6개의 결과만 확인해 보았다.



![image](https://user-images.githubusercontent.com/105009129/174097881-5a9fea31-3ade-4a5c-8257-902a299451a9.png)

trained parameter를 저장할 path를 같은 위치로 설정해줬다. epoch을 10으로 설정했다.

![image](https://user-images.githubusercontent.com/105009129/174097996-c5475da7-c657-45f8-b4cc-35bba4b432ef.png)



![image](https://user-images.githubusercontent.com/105009129/174098127-6ba2f870-9c5d-4445-aa58-41feea4964d1.png)


![image](https://user-images.githubusercontent.com/105009129/174098191-a0dbf11b-4932-4b4a-8a32-fc52d319cb6e.png)



![image](https://user-images.githubusercontent.com/105009129/174098231-b4ca783c-079e-49d4-aaea-dfafdac604cf.png)


![image](https://user-images.githubusercontent.com/105009129/174098302-fe2b97a2-5022-4cba-96e6-5c4485660287.png)


train 코드를 실행한 결과는 위와 같다. 눈을 뜬 사진에 대해서는 1이 라벨링되어있고, 눈을 감은 사진에 대해서는 0이 라벨링되어있다. epoch를 10으로 했을 때 train loss는 0.01338까지 줄었고, acc는 99.625까지 증가했다. size가 작은 이미지기에 epoch이 작아도 비교적 정확한 분류가 가능했다.


![image](https://user-images.githubusercontent.com/105009129/174098675-02f7ccc2-74ab-4f3d-8662-b07da15ac7c3.png)


![image](https://user-images.githubusercontent.com/105009129/174098876-df83fa37-2512-459a-b5c2-5f11417c5475.png)

![image](https://user-images.githubusercontent.com/105009129/174098921-eadde198-708f-4e05-a9cc-d1453615fdcb.png)

![image](https://user-images.githubusercontent.com/105009129/174098974-18161b58-cfdd-408e-985e-a592453b51e9.png)


Test 코드는 다음과 같다. 선언했던 accuracy를 통해 total acc를 구하고, 이를 count로 나누어 평균 acc를 구했다. 평균 accuracy는 99.65157%가 나왔다. 


train loss를 최소화하기 위해 epoch의 수를 50으로 늘려서 다시 training을 했다.

![image](https://user-images.githubusercontent.com/105009129/174103298-1798a3d6-3b19-4085-9577-e300ade1fe44.png)


![image](https://user-images.githubusercontent.com/105009129/174103356-e17e4984-8ade-4507-80d9-86feabccef2c.png)


정확도가 낮아졌는데, 유의미한 변화는 아닌 것 같다. 

IV. Related Work 
https://ultrakid.tistory.com/12
https://wjh2307.tistory.com/21

https://github.com/kairess/eye_blink_detector/blob/master/README.md
https://github.com/yunseokddi/Pytorch_dev/tree/master/sleep_detect


VI. Conclusion: 

AI Hub에서 제공하는 '졸음운전 예방을 위한 운전자 상태 정보 영상 소개'를 먼저 다운받은 후 이를 가공할 방법을 여러번 시도해봤었다. 이 dataset으로 실제 운전자의 눈 뜬 상태/ 감은 상태를 구분할 수 있는 오픈소스 모델을 구현해보고자 했었는데, dataset 가공 실패로 다른 dataset을 사용하게 된 것이 아쉬웠다. 하지만 직접 training, test를 해보며 이미지 처리에 대해 공부할 수 있었다. 기회가 된다면 직접 dataset을 가공하여 training을 하는 프로젝트로 확장해보고 싶다.

